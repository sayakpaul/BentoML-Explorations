{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we wrap a TensorFlow model into a REST API using `BentoML`. The datasets used here are taken from [this](https://github.com/Nilabhra/kolkata_nlp_workshop_2019) repository. The notebook also takes references from [this](https://github.com/bentoml/BentoML/blob/master/examples/tf-keras-text-classification/tf-keras-text-classification.ipynb) example notebook from BentoML itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/train.csv')\n",
    "validation = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/valid.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9131, 3), (1142, 3), (1141, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ordered a biryani, and the taste of the Biry...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A nice place to hangout since it has both the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This place is awesome for having lunch or dinn...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got shell of egg in the egg roll. as a resul...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Their biryani is oily, with a bit disconcertin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  I ordered a biryani, and the taste of the Biry...  positive\n",
       "1  A nice place to hangout since it has both the ...  positive\n",
       "2  This place is awesome for having lunch or dinn...  positive\n",
       "3  I got shell of egg in the egg roll. as a resul...  negative\n",
       "4  Their biryani is oily, with a bit disconcertin...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food was excellent with surplus quantity. ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place nearer to the Gitanjali metro stati...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ordered for Aloo tikki with choley just now @0...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hatari is one of those restaurants that our fa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disappointing.......\\nThey have altered the ta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  The food was excellent with surplus quantity. ...  positive\n",
       "1  This place nearer to the Gitanjali metro stati...  positive\n",
       "2  Ordered for Aloo tikki with choley just now @0...  negative\n",
       "3  Hatari is one of those restaurants that our fa...  positive\n",
       "4  Disappointing.......\\nThey have altered the ta...  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This place is amazing. I think the best place ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place has been on my list for quite some ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What a wonderful cold winter evening it was. M...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BabBQ had always been a personal favorite when...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Know for its Deep Dish Pizza this place is sur...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  This place is amazing. I think the best place ...  positive\n",
       "1  This place has been on my list for quite some ...  positive\n",
       "2  What a wonderful cold winter evening it was. M...  positive\n",
       "3  BabBQ had always been a personal favorite when...  positive\n",
       "4  Know for its Deep Dish Pizza this place is sur...  negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I ordered a biryani, and the taste of the Biryani was beyond my expectations and the quantity was also enough comparatively to the price!\\nReally nice much appreciable'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing digits for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "\n",
    "def remove_digits(s):\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    res = s.translate(remove_digits)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(remove_digits)\n",
    "validation['text'] = validation['text'].apply(remove_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=None, lowercase=True,\n",
    "                             ngram_range=(1, 1), min_df=2, binary=True)\n",
    "\n",
    "train_features = vectorizer.fit_transform(train['text'])\n",
    "train_labels = train['class']\n",
    "\n",
    "valid_features = vectorizer.transform(validation['text'])\n",
    "valid_labels = validation['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "valid_labels = le.transform(valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Dropout(rate=0.2, input_shape=train_features.shape[1:]))\n",
    "for _ in range(2):\n",
    "        model.add(Dense(units=64, activation='relu'))\n",
    "        model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an EarlyStopping callback\n",
    "es_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are ready to train the model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9131 samples, validate on 1142 samples\n",
      "WARNING:tensorflow:From /miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "9131/9131 [==============================] - 2s 196us/sample - loss: 0.6264 - acc: 0.6360 - val_loss: 0.5555 - val_acc: 0.6926\n",
      "Epoch 2/15\n",
      "9131/9131 [==============================] - 1s 149us/sample - loss: 0.4975 - acc: 0.7652 - val_loss: 0.4268 - val_acc: 0.8187\n",
      "Epoch 3/15\n",
      "9131/9131 [==============================] - 1s 152us/sample - loss: 0.4002 - acc: 0.8261 - val_loss: 0.3978 - val_acc: 0.8292\n",
      "Epoch 4/15\n",
      "9131/9131 [==============================] - 1s 152us/sample - loss: 0.3352 - acc: 0.8606 - val_loss: 0.3991 - val_acc: 0.8301\n",
      "Epoch 5/15\n",
      "9131/9131 [==============================] - 1s 152us/sample - loss: 0.2935 - acc: 0.8778 - val_loss: 0.4092 - val_acc: 0.8275\n",
      "Epoch 6/15\n",
      "9131/9131 [==============================] - 1s 151us/sample - loss: 0.2598 - acc: 0.8912 - val_loss: 0.4165 - val_acc: 0.8292\n",
      "Epoch 7/15\n",
      "9131/9131 [==============================] - 1s 152us/sample - loss: 0.2276 - acc: 0.9102 - val_loss: 0.4389 - val_acc: 0.8284\n",
      "Epoch 8/15\n",
      "9131/9131 [==============================] - 1s 152us/sample - loss: 0.2004 - acc: 0.9224 - val_loss: 0.4545 - val_acc: 0.8301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x129f3d1d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features,\n",
    "                    train_labels,\n",
    "                    epochs=15,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(valid_features, valid_labels),\n",
    "                    callbacks=[es_cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].apply(remove_digits)\n",
    "test_features = vectorizer.transform(test['text'])\n",
    "test_labels = le.transform(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.5525 - acc: 0.7958\n",
      "Accuracy: 79.58%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_features, test_labels)\n",
    "print(\"Accuracy: {0:.2f}%\".format(results[1]*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the training and validation sets and retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, validation), axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=None, lowercase=True,\n",
    "                             ngram_range=(1, 1), min_df=2)\n",
    "\n",
    "features = vectorizer.fit_transform(data['text'])\n",
    "labels = le.fit_transform(data['class'])\n",
    "\n",
    "test_features = vectorizer.transform(test['text'])\n",
    "test_labels = le.transform(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Dropout(rate=0.2, input_shape=features.shape[1:]))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10273 samples, validate on 1141 samples\n",
      "Epoch 1/15\n",
      "10273/10273 [==============================] - 2s 207us/sample - loss: 0.6220 - acc: 0.6493 - val_loss: 0.5355 - val_acc: 0.7178\n",
      "Epoch 2/15\n",
      "10273/10273 [==============================] - 2s 165us/sample - loss: 0.4923 - acc: 0.7718 - val_loss: 0.4465 - val_acc: 0.8168\n",
      "Epoch 3/15\n",
      "10273/10273 [==============================] - 2s 165us/sample - loss: 0.4080 - acc: 0.8319 - val_loss: 0.4271 - val_acc: 0.8230\n",
      "Epoch 4/15\n",
      "10273/10273 [==============================] - 2s 168us/sample - loss: 0.3514 - acc: 0.8562 - val_loss: 0.4380 - val_acc: 0.8300\n",
      "Epoch 5/15\n",
      "10273/10273 [==============================] - 2s 169us/sample - loss: 0.3061 - acc: 0.8779 - val_loss: 0.4569 - val_acc: 0.8221\n",
      "Epoch 6/15\n",
      "10273/10273 [==============================] - 2s 166us/sample - loss: 0.2710 - acc: 0.8914 - val_loss: 0.4827 - val_acc: 0.7993\n",
      "Epoch 7/15\n",
      "10273/10273 [==============================] - 2s 167us/sample - loss: 0.2463 - acc: 0.9009 - val_loss: 0.5207 - val_acc: 0.8028\n",
      "Epoch 8/15\n",
      "10273/10273 [==============================] - 2s 164us/sample - loss: 0.2160 - acc: 0.9148 - val_loss: 0.5299 - val_acc: 0.7958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12f2285c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features,\n",
    "                    labels,\n",
    "                    epochs=15,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(test_features, test_labels),\n",
    "                    callbacks=[es_cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will use this model for serving. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing on a single test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = vectorizer.transform([remove_digits('I had a very bad experience you know.')])\n",
    "le.inverse_transform(model.predict_classes(test_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model saving and serving just got easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_classification_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile text_classification_service.py\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from string import digits\n",
    "from bentoml import api, env, BentoService, artifacts\n",
    "from bentoml.artifact import TfKerasModelArtifact, PickleArtifact\n",
    "from bentoml.handlers import JsonHandler\n",
    "\n",
    "@artifacts([\n",
    "  TfKerasModelArtifact('model'),\n",
    "  PickleArtifact('vectorizer')\n",
    "])\n",
    "@env(conda_dependencies=['tensorflow', 'scikit-learn'])\n",
    "class TextClassificationService(BentoService):\n",
    "    \n",
    "    @api(JsonHandler)\n",
    "    def predict(self, parsed_json):\n",
    "        text = parsed_json['text']\n",
    "        remove_digits = str.maketrans('', '', digits)\n",
    "        text = text.translate(remove_digits)\n",
    "        text = self.artifacts.vectorizer.transform([text])\n",
    "        prediction =  self.artifacts.model.predict_classes(text)[0][0]\n",
    "        if prediction==0:\n",
    "            response = {'Sentiment': 'Negative'}\n",
    "        elif prediction==1:\n",
    "            response = {'Sentiment': 'Positive'}\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./text_classification/TextClassificationService/0.0.2019_04_22_e5d9f7d0\n",
      "Dockerfile                \u001b[34mTextClassificationService\u001b[m\u001b[m requirements.txt\r\n",
      "MANIFEST.in               bentoml.yml               setup.py\r\n",
      "README.md                 environment.yml\r\n"
     ]
    }
   ],
   "source": [
    "from text_classification_service import TextClassificationService\n",
    "\n",
    "# Construct the vectorizer once again for the artifact\n",
    "vectorizer = CountVectorizer(stop_words=None, lowercase=True,\n",
    "                             ngram_range=(1, 1), min_df=2)\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/train.csv')\n",
    "validation = pd.read_csv('https://raw.githubusercontent.com/Nilabhra/kolkata_nlp_workshop_2019/master/data/valid.csv')\n",
    "\n",
    "def remove_digits(s):\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    res = s.translate(remove_digits)\n",
    "    return res\n",
    "\n",
    "train['text'] = train['text'].apply(remove_digits)\n",
    "validation['text'] = validation['text'].apply(remove_digits)\n",
    "\n",
    "data = pd.concat((train, validation), axis=0)\n",
    "\n",
    "vectorizer.fit_transform(data['text'])\n",
    "\n",
    "features = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Save and serve\n",
    "svc = TextClassificationService.pack(model=model, vectorizer=vectorizer)\n",
    "saved_path = svc.save('./text_classification')\n",
    "print(saved_path)\n",
    "!ls {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': array([[1]], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict({\"text\": \"I had a wonderful experience eating their chicken noodles! Also loved the ambience.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Correct! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R {saved_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
